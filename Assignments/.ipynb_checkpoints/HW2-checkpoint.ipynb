{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    " 1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    " \n",
    " 2- Normalize data by rescaling them to (0,1) \n",
    " \n",
    " 3- Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    " \n",
    " 4- Define Model\n",
    "    * Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "    * Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    * Outout Layer: Fully Connected + Softmax Activition\n",
    " \n",
    " \n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Dense(128, activation='relu')\n",
    "    5. Dense(num_classes, activation='softmax')\n",
    "\n",
    "    Also build another model with BatchNormalization and Dropout.\n",
    "    Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train/np.max(x_train)\n",
    "x_test = x_test/np.max(x_test)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "x_train = np.reshape(x_train,[-1, 28*28])\n",
    "x_test = np.reshape(x_test,[-1, 28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2995 - accuracy: 0.9154\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2933 - accuracy: 0.9172\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2872 - accuracy: 0.9190\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2819 - accuracy: 0.9206\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2769 - accuracy: 0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x165a98c9430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=500, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  0.26390978693962097\n",
      "Accuracy =  0.9265000224113464\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"Loss = \", loss)\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2721 - accuracy: 0.9237\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2677 - accuracy: 0.9247\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2634 - accuracy: 0.9259\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2592 - accuracy: 0.9274\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.2555 - accuracy: 0.9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x165a9d97760>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28,28,1), activation='relu'))\n",
    "model_2.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "model_2.add(Dense(10, activation='softmax'))\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=500, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  0.24545717239379883\n",
      "Accuracy =  0.9301000237464905\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"Loss = \", loss)\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.1522 - accuracy: 0.9574\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.1504 - accuracy: 0.9578\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.1490 - accuracy: 0.9583\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.1477 - accuracy: 0.9584\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.1464 - accuracy: 0.9589\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28,28,1), activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(128, activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(10, activation='softmax'))\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_3 = model.fit(x_train, y_train, batch_size=500, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  0.15106846392154694\n",
      "Accuracy =  0.955299973487854\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"Loss = \", loss)\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
